# Fine-tuned BERT для защиты LLM от Jailbreak-промптов (фильтр на входе)

Этот проект включает код для обучения модели BERT, способной классифицировать запросы на две категории: **Jailbreak** и **Regular**. Модель использует предобученную архитектуру BERT, которую мы дообучаем на кастомном наборе данных https://github.com/verazuo/jailbreak_llms.git

## Описание проекта

- Подготовка данных: загрузка, очистка, объединение нескольких CSV-файлов.
- Токенизация данных с использованием `transformers` (BERT Tokenizer).
- Обучение модели BERT для бинарной классификации.
- Оценка производительности модели с помощью метрик, таких как **Confusion Matrix**, **ROC-AUC**, и других.
- Сохранение модели для последующего использования.

## Основные функции

1. **Обработка данных**:
   - Удаление ненужных столбцов.
   - Добавление меток (1 - Jailbreak, 0 - Regular).
   - Объединение данных из разных источников.

2. **Обучение модели**:
   - Использование `BertForSequenceClassification` из библиотеки `transformers`.
   - Оптимизация с помощью AdamW.
   - Обучение на GPU или CPU.

3. **Оценка модели**:
   - Матрица ошибок.
   - Отчет по классификации.
   - ROC-AUC и Precision-Recall кривые.

4. **Тестирование**:
   - Проверка модели на новых примерах.
   - Использование сохраненной модели для классификации текстов.

---

# Fine-tuned Llama 3.2 1B (unsloth) для классификации Jailbreak-промптов

В дополнение к модели BERT, данный проект также включает оптимизированную модель **Llama 3.2 1B (unsloth)**, которая собой более мощную модель с 1 миллиардом параметров и с использованием FP8-квантования, BF16б, RoPE, QLoRA и т.д

## Описание проекта для Llama 3.2 1B

Модель **Llama 3.2 1B (unsloth)** была оптимизирована для обработки более сложных запросов с минимальными затратами вычислительных ресурсов. В данном проекте она используется для тестирования и внедрения защиты, основанной на модели BERT, с целью улучшения точности классификации Jailbreak-промптов. 
